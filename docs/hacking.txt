This requires the source checkout from GitHub,
e.g. https://github.com/brendano/ark-tweet-nlp

The checkout should have all necessary resources EXCEPT a trained model.  One
can be downloaded from http://www.ark.cs.cmu.edu/TweetNLP (it is packaged with
the released version).

Setting up Eclipse
==================

We use the following procedure to set up Eclipse for development. The tricky
bit is to get the jar dependencies by invoking Maven. There may be other ways
of doing it.

(1) Type: "mvn package". Among other things, this downloads all dependencies
    into ark-tweet-nlp/src/target .  It also puts tons of crap into ~/.m2.
(2) Go to Eclipse and refresh the directory (e.g. F5)
(3) In Eclipse, go to the project's
    Properties -> Java Build Path -> Libraries -> "Add JARs".
    Add jars from:
    (a) lib/
    (b) ark-tweet-nlp/src/target/bin/

Once Eclipse is done compiling all the source files, then we use scripts/java.sh
to train and run the tagger. It invokes "java" with all dependencies and
Eclipse-compiled .class files on the classpath. So you can tell Eclipse to build
files (and in fact this happens automatically), then switch to the terminal to
run the tagger.


Resources
=========

The resource files, including the model, word clusters, etc. go into
ark-tweet-nlp/src/main/resources/cmu/arktweetnlp/

Then the resource loader can find them.  "mvn package" puts them into jar file
too.
